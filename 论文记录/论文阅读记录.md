## 《面向热点话题型微博的情感分析研究》-哈尔滨工业大学-硕士学位论文-张想

第一部分:主客观分析与极性判别
主观性识别是情感分析的第一步；
极性:积极 / 消极


第二部分:评价对象抽取(监督/半监督)
S1. 获取候选评价对象：抽取名词 / 名词短语
S2. 过滤无关评价对象
聚类相似度度量：Hownet度量；词语覆盖率(类似Jaccard系数)/Average-Linkage距离
注：根据表4-8和图4-11，衡量聚类算法的指标是每个类的纯度？

第三部分:热点话题情感分析
S1. 主客观分类，得到主客观标签；
S2. 评价对象抽取
S3. 评价对象聚类


根据结果来看，这篇文章主要是研究：针对某一话题下的微博，消极与积极的比例，以及每一条具有主观感情的微博的评价对象有哪些(例如图5-5)


## CCS2018 - Deep Fingerprinting Undermining website fingerprinting

* 首先要明确Website Fingerprinting的概念：用户为了隐私会选用Tor来隐藏自己真是访问的网站及行为，在此情况下，攻击者通过Website Fingerprinting来打破Tor的保护，来发现用户真实访问的网站和真实行为。

* 通过Website Fingerpinting打破Tor保护的方法一般是：通过收集流量中的数据包进行分析(数据包流向、大小等)并结合已知网站的样本作为训练集，通过机器学习分类算法判断用户真实访问的站点。

* 此文使用了CNN来进行分类算法。

* 疑问是：这样做的新颖在何处？(用了CNN?)

* 文中提到了AutoEncode，这个以后要学习。

* 文章详细讲了数据的收集，以及closed与open两类数据的情况。


## USENIX2018 - Who Is answering My Queries:understand and characterizing Interception of the DNS Resolution Path(纸质)

* 提出了，当用户自己设定了递归DNS服务器时(如8.8.8.8),其向8.8.8.8的请求会被某个alternative DNS resolver阶段，之后的操作都是由alternative DNS resolver进行的。

* 然后研究了 **发起请求用户的AS分布**，**被intercepted的公共DNS的AS分布**和**alternative DNS resolver的ASf分布**.

* 注意在**Our Approach**中提出的**如何检测出DNS数据包被截断的方法**

* DNS intercepte的好处是
   
   * improve the performance of DNS Lookup(减少RTT)

   * 提高“安全性”,alternative DNS resolver是被(ISP)信任的DNS服务器

   * Reduce financial settlement

## NDSS2018 - Kitsune : An Ensemble of Autoencoders for Online Network Intrusion Detection

* **具体没看懂，只整理下来大概**

* 核心:对神经网络进行集成以实现入侵检测(an ensemble of neural networks)

* 优点:可以进行**无监督学习训练**。反之，有监督训练只能再已打好标的数据进行，是一种closed-world approach，对训练集中未出现过的数据无法很好预测的缺点。

* Kitsune的异常检测算法KitNET有一个主要的参数：the maxinum number of inputs

* Feature Map和 Anomaly Detector 细节没有看很懂，感觉是深度学习基础不够

## NDSS2018 - Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks

* 本文主要讲述了检测神经网络训练样本中的adversarial examples

* 进行此研究的原因：

    * 通过发现Adversarial Samples发现背后的攻击者

    * 排除出adversarial samples / input

    * adversarial samples 可能使benign samples 被预测为malicious

* 一般的对抗方法

    * Adversarial Training: the model will learn how to restore the ground truth from the adversarial perturbations and perform robustly on the future adversarial examples

    * Gradient Masking： reduce the sensivity of DNN models to small changes in inputs

    * Input Transformation: reduce the model sensitivity to small input changes by transforming the inputs

* 一般检测Adversarial Examples的方法：

    * Sample statistic: 通过正负样本统计进行，但这一方法需要大量的正负样本为基础；

    * Training a Detector: 通过负样本训练一个负样本检测分类器，但缺点是这种方法需要以大量adversarial samples为基础；

    * Prediction Inconsistency： the basic idea of prediction inconsistency is to measure hte disagreement among several models in predicting an unknown input, since one adversarial example may not fool every DNN model.

* 本文提出的方法：

    * reducing color bit depth (这一方法应该是针对图像？？)

    * spatial smoothing

* 本文实验数据：MNIST数据集，CIFAR-10, ImageNet


## RAID2018 - DNS Unchained: Amplified Application-Layer Dos Attacks Against DNS Authoritatives

* 本文提出了新的几种在application-level针对DNS 权威服务器的攻击方法，并总结了可行的解决方案

* 传统针对DNS的DDOS攻击：DNS Water Tortue attacks
    * DNS Water Tortue attacks -- also known as random prefix attacks -- flood the victim's DNS servers with requests such that the server runs out of resources to respond to benign queries.

    * 这一攻击的缺陷是：
        * the attack traffic show exceptionally high failure rates for particular domains

        * the attacks provide no amplification, as every query by the attacker eventually results in only a single query to target ANS -- unless queries are resent in case of packet loss.

* New DDos

    * 利用CNAME的“链式”解析或者说递归解析，使递归不断向同一DNS权威服务器发起请求；

    * 修改TTL使cache很快消失， 递归服务器不断向权威服务器发起请求；

    * DNAME：类似CNAME链式解析的原理。DNAME也是一种资源记录，具体可见此文https://ssorc.tw/994或RFC文档

* 对抗New DDos的方法

    * 通过Zone Files检测出CNAME

    * TTL值

    * 限制RRL: 限制某个client IP 接收 DNS响应的频率 / 限制ANS 进行DNS响应的频率

    * Back-off Strategy:give loaded ANS time to recover

    * 限制递归查询深度(针对CNAME和DNAME)


## NDSS2015 - NDSS2015-Parking Sensors Analyzing and Detecting Parked Domains

* 提出了检测Parked domains的方法

* 文中首先介绍了常见的Parked domains的目的，产生方式等

* 抽取特征，通过Random Forest进行检测

* Paper代码https://github.com/kdsec/Domain-Parking-Sensors，但是并没有包括模型训练部分的代码，可详细看看typosqlating domains的产生方法。

### 关于特征，主要分为四类

* HTML Features:HTML features are extracted from the source code of every load frame so that we can we can analyze the content and the scripts deployed on the page.

    * **Average and maximum link length**, **Averate source and external source ratio**, **External link and external source ratio**, **website director presence**, etc.

* HAR features:these features are derived from the HTTP archive that is constructed while loading a page and we focus on the characteristics of HTTP requests.

    * HAR: HTTP Archive, a JSON formatted archive file for logging of a website's interaction with a site.

    * the features such as **third-party requests ratio**, **third-party data ratio**, **Initial response size and ratio**, etc.

* Domain name feature: focus on characteristics inffered from domain name itself, especially **typosquatting doamins**.

* Frame Features: the features which are extracted by tracking every loaded frame on the webpage
    
    * such as **amount of frames**, **main frame and iframe redirections**, **different final domains**

* 补充:the NS or CNAME of domain: Parking domains' NS or CNAME is commonly set to parking services.

* Ecosystem of Domain Parking

![](http://ouzh4pejg.bkt.clouddn.com/ecosystem%20of%20domain%20parking.png)

## Var-CNN and DynaFlow: Improved Attacks and Defenses for Website Fingerprinting

* the crontributions of the paper:

    * Coming up with Var CNN which can extract features automatically 

    * Coming up with a new Defense --- DyanFlow

* The code of the paper: https://github.com/lsvih/Var-CNN--DynaFlow

* 文章大致浏览，主要在看代码。https://github.com/lsvih/Var-CNN--DynaFlow/blob/master/var_cnn_ensemble.py是利用Keras的CNN。疑问是，一般是通过model.add()来添加卷积层、池化层(model.add(MaxPooling1D(...)))等，而此文中则是model = MaxPooling1D()(model)的方法。

## USENIX2014 - Understanding the dark side of Domain Parking

* the contributions of the papper:

    * The paper performed the first systematic study of ilicit study of illicit activities in parked domain monetization and infiltrated domian parking services and collect a set of complete monetization chasins.

    * confirm the presence of illegitimate operations including **click fraud**, **traffic spam** and **traffic stealing**.

    * reveal the pervasiveness of those activities which affect most leading parking service providers and attribute it to account for up to 40% of total revenue.

    * the discovery of unique feature of illicit activities and their relations with different monetization strategies and parking service syndicates.


### 

* The most monnon way for setting a domain for parking is through te DNS, in which the parked domain's NS or CNAME is set to point to that of parking service.

* Monitization option

    * Search advertising: (没看懂。。。)

    * PPC(pay-per-click): Once the domain is clicked, the owner woule get the profie.

    * Direct Navigation Traffic(PPR, pay-per-redirection): Direct Navigation traffic is generated when the web user enters a domain name as a query and exptects to be redirected to a related domain.

* 其他部分文章分析了Parking domain获利的ecosystem,不进行细致整理，整理一些新的概念；

* Click fraud: 

* Traffic Spam: Purchsing campaigns recieved 306 traffic hits from our crawler through domains parked with parking services.(我的理解：通过parking domains为特定组织的站点提升访问流量，即凡对parking domain进行访问的，访问量均将被记录的特定站点的访问量里面)

* Traffic Stealing: Occasionally parking services were found to be dishonest with domain owners, failing to inform them for part of the revenue they were supposed to share with the owners.

### Fingerprinting Monetization Chains

The paper developed a technique that fingerprints the monetization options observed on seed chains.

* Method

    * The idea: The problem of detecting illegitimate operations comes down to identifying the monetization options they involved. 
        * The paper found that the sequence of URL patterns can be used to determine the presence of a monetizaation option. (The details can be found in the paragraph of 4.1-The idea.)

    * URL-IP Cluster(UIC) generation: An ad network can have many affiliated websites and each site may have multiple domains and IP addresses. A UIC includes a set of IP addresses for related hosts and the invariant part of the URL(without the host name) across all members in the cluster.


## ICML2018-Ultra Large-Scale Feature Selection using Count-Sketches

一篇人工智能A类，具体没有太看懂，但几类几个新概念

* Feature Hashing: 特征哈希法的目标是把原始的高位特征向量压缩成较低维特征向量，且进来不损失原始特征的表达能力。

* Greedy threshholding: 用贪心算法的思想选择阈值？？

* SGD(Stochastic gradient descent):随机梯度下降，每次随机选择一个样本进行训练。

* IHT(Iterative hard threshholding):迭代硬阈值，

* Count Sketch:一种算法，具体可Google


## ECML-PKDD 2017 - Malware Detection By Analysing Encrypted Network Traffic with Neural Networks

一篇CCF B类

可以参考这个[链接](https://mp.weixin.qq.com/s/P6OTaj67hwHUKaI7jxSAOA)

自己整理的和这个差不多

## USENIX 2018 - FANCI  Feature-based Automated NXDomain Classification and Intelligence

如果把里面的模型换为神经网络？？？

## NDSS2018 Modeling-based Causality Inference in Audit Logging for Attack Investigation

* 论文完全没有看懂，但是“基于因果关系推理”的思想是自己第一次见到，觉得以后很可能用到。

* [一位师兄关于此文的笔记](https://mp.weixin.qq.com/s/plCWVKeIyMct71ybzBDq7A)

* 一篇文章:[学习因果关系和基于因果关系的学习](https://mp.weixin.qq.com/s/w5yWzqa5-xO41oDW1W1MSw)


## Inline DGA Detection with Deep Networks

### 简要记述如下

* 没有使用已知的DGA domains,而是直接从流量数据中提取 ( real time stream obtained from Farsight Security)

* 作者根据DGA域名的特点，从raw data中提取positive examples & negative examples

    * We take as negative examples (legitimate
domains) those domain names which have been resolved at least once, never resulted in an NXDomain response, and
span more than 30 days.


* 作者用的都是基于字符的特征，因此先根据ASCII得到字符id,然后进行embedding, **后续特征的计算都是根据embedding进行的**

* 作者使用了CNN 和 LSTM


### 优势

* 这是直接从数据中进行学习的，属于online 检测；

### 疑问

* 为什么会用CNN? 从道理和逻辑来讲说得通吗？？ 


## KDD2018-Graph Classification using Structural Atention

* 要点: **Graph + Attention**

* 参见[KDD2018-Graph Classification using Structural Atention](http://ryanrossi.com/pubs/KDD18-graph-attention-model.pdf)

### 没有读全文，大致概述如下：

由于图的稀疏和图中噪声信息的存在，某些情况下对图进行表示是没有必要也很耗费计算资源的。因此加入Attention机制，每一步只获取足够做出当前决策所需的图中节点信息。


## KDD2018-RL to rank in e-commerence search engine formalization ayalysis and application

* 核心：Reinforcement Learning

* 链接: [KDD2018-RL to rank in e-commerence search engine formalization ayalysis and application](https://www.kdd.org/kdd2018/accepted-papers/view/reinforcement-learning-to-rank-in-e-commerce-search-engine-formalization-an)

* 没有通读，注意关注对**问题建模与表示的过程**


## AAAi2018-convolutional 2D Knowledge Graph Embeddings

大体明白了，但pytorch的代码看得不是很懂

* 用基于conv2d的embeddings预测knowlendge graph中的实体间关系

* 一篇解读： http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5/

* 代码：https://github.com/TimDettmers/ConvE

* [论文解读](http://blog.openkg.cn/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D-%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5/)

    * 最重要的一段话：这是 ConvE 的整体结构，把输入的实体关系二元组的 embedding reshape 成一个矩阵，并将其看成是一个 image 用卷积核提取特征，这个模型最耗时的部分就是卷积计算部分，为了加快 feed-forward 速度，作者在最后把二元组的特征与 KG 中所有实体的 embedding 进行点积，同时计算 N 个三元组的 score（即1-N scoring），这样可以极大地减少计算时间，实验结果显示，KG 中的实体个数从 100k 增加到 1000k，计算时间也只是增加了 25%。

    * 核心就是paper中的**Figure1**

## Community Finding of Malware and Exploit

* 基于商品和商品类别，计算vendors间的相似性，从而发现vendors构成的community

### 步骤：

* 构建商品和vendors的二部图

* 根据商品名的n-gram对商品进行聚类

* 将Marketplaces分为两个不相交的集合[这里没有十分懂]

* 根据商品和商品类别关系、vendors和商品关系，构建商品类别和vendors之间的二部图

* 根据vendors和商品类别间的关联，构建vendors之间的关联图(参见paper中Figure2 中a,b,c的演进)

* 计算vendors间相似性：构建表示vendors和product category之间关联的0/1矩阵，用(Jaccard Similarity)计算vendors之间相似性，相似性的值作为vendors之间关联图中的权重

* 根据Louvain heuristic方法去发现community

* community的验证：用ARI(Adjusted Rand Index,一个聚类结果的评价指标)对community进行验证与评价

### Key

二部图构建，community发现

### 疑问

文中为什么要构建两个Set???


## Classifying Illegal Activities on Tor Network Based on Web Textual Contents

* 基于文本对DarkWeb Illegal Activities进行分类

### 学习到的点有：

* Table1对Illegal Activities划分的26类；3.2 Dataset Characteristics中还列举了其他分类方法；

* 对于多分类问题中类别数据不平衡的问题，作者采用了**the class-weight parameter in Scikit-Learn Library**,几个参考链接如下：

    * https://www.zhihu.com/question/265420166

    * https://codeday.me/bug/20180427/157786.html

* 多分类评价指标: **macro-P/R, micro-P/R**, 可参见此文[https://www.cnblogs.com/robert-dlut/p/5276927.html](https://www.cnblogs.com/robert-dlut/p/5276927.html);此外，多酚类评估还有**宏平均、微平均**等，可见[https://www.cnblogs.com/robert-dlut/p/5276927.html](https://www.cnblogs.com/robert-dlut/p/5276927.html)


## Mining Key-Hackers on Darkweb Forums

* 基于Darkweb Forums对用户的reputaion scores, 通过context,social_networks和seniority analysis得到25个特征，判断users是否是hackers.

* 本文认为Darkweb Forums打分Top10%的用户是hackers,以此作为ground truth;

* 本文的判断方法有两大类，一是根据25个features也计算一个分数，取Top10%作为预测的hackers;另外是通过RF或SVM进行二分类；


* 注意的是contributions中说一个forum可行的方法在其他forum也可行，具备**迁移性**


## ICJAI2018 - Translating Embeddings for Knowledge Graph Completion with Relation Attention Mechanism

* 读了大概

* Knowledge Graph Completion,即Graph Completion中的link prediction问题

* 本文提出的方法大致分为两步：先确定entity candidate的类别；然后再确定具体的entity;

* 疑问

    * Attention体现在什么？ two states的过程就是Attention的体现吗?

    * 文中讲的是entity的预测，但又说是link prediction的任务，到底应该是什么？？


## CVPR2018-Zero shot Recognition via Semantic Embeddings and Knowledge Graph

* 代码: [https://github.com/JudyYe/zero-shot-gcn](https://github.com/JudyYe/zero-shot-gcn)

* 新学到的两个概念

    * Zero-shot learning(零样本学习) 指的是我们之前没有这个类别的训练样本。但是可以学习到一个映射X-Y

    * One-shot learning(单样本学习) 指的是我们在训练样本很少，甚至只有一个的情况下，依旧能做预测

    * 相关名词还有trans learning, domain adaption

    * Zero/One-shot learning都属于transfer learning,要点在于先学到好的X-Y关系，希望能应用到其他问题上


* 本文的zero-recognition: 在n个类别中只有m个类别具有足够(visual examples)数据可供学习，剩下的n-m个类别要通过...（For the remaining n−m categories, we want to estimate their corresponding weight vectors given their embedding vectors as inputs.）

* Task：

    * 预测没有图片样本的图片类别

    * 给出一个未曾见过类别名词的embeddings和包含相关关系的知识图谱，预测出这个未知的类别来

    * 输入：类别即类别的semantic embeddings;
    * 输出：类别

    * 根据类别间关系建立知识图谱，每个类别作为一个节点，两个类别间如果存在关系则节点间建立连接；建立的图用邻接矩阵表示。

    * 举例：虽然没有okapi的图片，但根据对okapi文字描述的向量和知识图谱中okapi与zebra的关系，学习出在没有okapi图片做训练数据的情况下，能够判断出okapi的图片分类器。

* 疑问

    * 将okapi类别的词向量转化为category后，怎么和图片建立关系？ 

    * 文中说输出是classifier, 怎么输出classifier?是参数？


* 学到的东西：

    基于关联关系，由已知得到未知。


## Heterogeneous Supervision for Relation Extraction A Representation Learning Approach
    
    * 文中2-1,2-2给出了Relation Extraction和Heterogeneous Supernision的定义

    * 看了一半，不是很懂。。。。


## KDD2018-INteractive Paths Embedding for Semantic Proximity Search on HEterogeneous Graph

* 一篇很好的记录: https://blog.csdn.net/travalscx/article/details/84779218

* 论文代码 https://github.com/shuaiokshuai/IPE

* 从v到p的不同路径能够提取到不同信息，因此要以入interactive paths

* 文中构建interactive path的步骤如下：
    
    * 1 添加关联： 在path之间添加interdependencies构成有向图

    * 2 删除可能形成的环.  注意**Removing Cycles**中提出的删除环的方法，及用r计数的方法

    * 3 构建interactive path structure

* Embedding: 使用Interactive GRU将interactive path structure构成embedding

    * 使用前导点的三点考虑+LSTM的门–>节点的向量–>maxpooling成path的向量–>structure的向量–>multiple structure的向量–>最终promixity embedding向量


* 思考
    
    * 层级递进进行embedding学习的方法：node -> path -> structure -> multiple structure -> proximity embedding

    * GRU各个门的定义和initial hidden states的定义

## KDD2018-NetWalk:A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks

* 作者提出了一种对动态网络进行embedding、然后通过聚类进行异常网络中异常点、异常边检测与发现的方法。
整个系统主要两部分：Network Embedding + Anomaly Detection

* 对网络进行embedding的方法：clique embedding

    * 大致过程是：deep autoencoder + 最小化每一步的pairwise误差 (3.2)
    
    * 对节点的embeddign误差目标函数由四部分组成：autoencoder的重构误差、pairwise distance、基于sparse auto-encoder的KL散度和权重Decay
    
    * 对节点embedding目标函数求最优时引入了"error terms"(作者类比BP算法引入的一种计算方式)

    * 对边的embedding:
        * 对于新加入的边通过lookup_table编码；
        * 本文考虑的是无向网络
        * Handamard operator的edge embedding方法

    * 当网络动态变化时(Network Representation Maintenance)，通过周围点进行替换。具体见3.4

* 基于聚类的异常检测

完成network embedding后，进行聚类得到若干cluster；对于新加入node或edge,若聚类后不属于某个已有cluster，则认为是异常的。

* 启发

    * 这种对动态网络建模分析的方法应该很实用，不管是domain-ip关系、社交网络或其他，都可能用到这种建模方法

    * 文中提到不仅是对node进行ananomy detection,还有对edge的ananomy detection

    * 注意思考node embedding损失函数设定的意义，是考虑了哪些因素

* 问题
    
    * pairwise distance不是很理解；

    * 对输入的表示形式还是不能很理解。   怎么体现第几个walk??


## KDD2018-Text Truth an Supervised Approach to Discover Trustworthy Information from Multi-Sourced Text Data

* 在用户给某问题给出的答案中，找出trustworthy的若干个点(计算trustness score)

* 难点
    
    * 用户给出的答案很难是全面的

    * 用户给出的答案中，可能若干个点正确，又有另外若干个点是错误的

    * 考虑一词多义问题

* 大致方法:从原始answer中提取出若干个keywords，在考虑user reliability的情况下学习出keywords的embedding表示 对keywords聚类.聚类后根据answer 中keywords所属cluster的情况计算sorce.

* Generative Model: 
    
    * learns the answer factors and their truth label  (factors就是指key points)

        * 通过Standford POS-Tagger提取answer中的关键词

        * 通过Dirichlet distribution产生the mixtrue of factors (QUESTION:公式1中怎么知道K_<sub>q应该是多少？)

        * 产生每个factor为True的先验可能性γ，它满足Beta分布

        * 根据γ(先验分布)和Bernoulli distribution产生truth label

    * generate user reliability

        * 在假设已知每个问题answer factors和他们对于truth label的情况下，用类似FN、TN的指标评价use reliability

    * Observation Modeling

        * 首先产生一个binary indicator y,表示answer中的第k个factor是否应该属于用户u的答复(whether it should be covered by user u)。注意y服从Bernoulli distribution.
        
        * 计算answer中第m个关键词的factor label,见文中公式7。由公式的计算过程可见，这一过程考虑了user reliabilities和semantic meaning (answer factor mixture distribution & user reliabilities)
        
        * 计算keyword embeddings
        
    * Trustworthy-Aware Answer Scoring
    
        * 给出每个问题相关的truth labels,然后统计用户给出answer的keywords中属于(clustered into factor k)这些truth labels的数量，用公式10计算。
        
        * 根据Overview,这里应该是已知answer应包含的key points(factor)的cluster,然后对当前answer中keywords进行聚类，再根据公式10进行统计。

* Model Fitting       
        
    * 通过MCMC(蒙特卡洛-马尔科夫链)等方法估计模型参数，进行model fitting。

### 问题与思考

* 这篇文章在模型建立过程中用了很多统计学相关知识(Beta Distribution、Dirichlet Distribution、Bernoulli distribution 和 vio Mises-Fisher distribution)

* 相似的思路能否用于舆情分析和其他方面？

* 问题：文中对计算trustworthy score时的聚类过程描述太少了


## KDD2018-Takogen Unsupervised Topic Taxonomy Construction by Adaptive Term Embedding and Clustering

### 做了什么

* 一句话概述:基于Sphirical Clustering和Term Embedding构建文档主题分类系统，实例如Figure 1所示。

    * We propose an unsupervised method named TaxoGen for constructing topic taxonomies. It embeds the concept terms into a latent space to capture their semantics, and uses term embeddings to recursively construct the taxonomy based on hierarchical clustering.

* 整个的流程应该是: 获取sub-topic下的documents(先对) --> 学习term在sub-docs中的local embeddings --> 进行聚类(聚类时计算representativeness score, scored低的会被作为general term而push up)

### 难点

* 确定term的合适的level是困难的

* 基于所有语料学习的embedding是存在一定问题的。例如，machine learning和reinforcement learning具有相似的上下文，因此会具有相似的embeddings, 这对后续发现machine learning相关的topic是困难的。


### 系统概要

* 输入
    * 文档集合 D

    * seed terms(seed terms are key terms from D, representing the terms of interest for toxonomy construction). seed terms可以是人工提取。

系统主要包括两部分

* Adaptive Spherical Clustering Module(allocating terms to proper levels when splitting a coarse topic; 通过计算representativeness score和迭代的聚类来发现general terms并重新定义cluster的边界)

    * allocating terms to **proper levels** when splitting a coarse topic. Relying on a **ranking function that measures the representativeness** of diﬀerent terms to each child topic, the clustering module **iteratively
detects general terms** that should remain in the parent topic and keeps **refning the clustering boundaries** of the child topics. 

    * 聚类
        
        * 首先把所有terms置于C_sub中，然后迭代地识别general terms并提炼sub-topics。在每次迭代时，会计算当前term与在当前sub-topic中的representativeness, 如果计算结果小于阈值，则它不属于这个sub-topic,将它作为general term进行push up。聚类过程一直进行，直到没有新的general term被检测出来。

    * 计算Representativeness

        * representative term要满足的条件是: a representative term for S_k should appear frequently in S_k but not in the sibling topics of S_k

        * 计算representativeness需要使用属于S_k 子话题中的文档, 作者选用TF-IDF获取属于每个topic的文档
           (获取子文档的方法在4.3中描述：可以是cluster based 和 retrieval based)

        * 关于计算concentration时的BM25: BM25（Best Match25）是在信息检索系统中根据提出的query对document进行评分的算法,是一种常见用来做相关度打分的公式。

            * https://www.jianshu.com/p/1e498888f505


* Local term embedding模块(在每个topic内的文档中，学习出term的local embeddings)

    *  uses **topic-relevant documents** to learn **local embeddings** for the terms in
each topic. The local embeddings capture term semantics at a fine granularity and are **less constrained by the terms irrelevant to the topic**. 

    * 用**Skip-Gram model**计算Local Embeddings

    * 注意，local embedding的计算只是以sub-topic下的docs作为语料进行计算，sob-topic下docs的获取方法有如下两类:

        * cluster based: We derive the cluster membership of each document d ∈ D by aggregating the cluster memberships of the terms in d using TF-IDF weight. The documents that are clustered into topic C are collected to form the sub-corpus 

        * retrieval based: 使用doc中所有词的tf-idf的均值作为doc的embedding表示, 然后使用当前topic下的mean directioon去取回所相似的M个文档(查找与mean direction最相似的M个文档)

    * 实际操作中，主要用第一种方法获取sub-docs,用第二种方法进行补充


* 关于DBLP数据集: https://blog.csdn.net/frontend922/article/details/18552077

* 关于BM25的讲解和示例代码: https://www.jianshu.com/p/1e498888f505

* Hierarchy Latent Dirichlet Allocation

    * [通俗理解LDA模型](https://blog.csdn.net/v_july_v/article/details/41209515)

        * 文末有邹博讲解的PPT链接

    * [LDA数学笔记](https://yanshengjia.com/2017/12/16/LDA-%E6%95%B0%E5%AD%A6%E7%AC%94%E8%AE%B0/)

    * LDA: 给定一篇文章，推测其文章主题