# 评价指标

* 精确率：即precision,是被正确检索到的样本数量与检索到的全部样本数量之比，是对检测结果精确率的衡量，因此又称“查准率”;
    
* 召回率: 即recall,是被正确检索到的样本数量与应当被检索到的样本数量(或原本具有的样本数量)之比，是对检测结果是否全面的衡量，因此又称“查全率”；

* F1-score: F-Measure是总和考虑Precision和Recall而提出的衡量标准，它是Precision和Recall的**加权调和平均**，其计算公式如下所示。

    * 当式中β=1时，即得到F1-score,如果认为Precision更重要，则减小β，若认为Recall更重要，则增大β；

![f-Measure](https://raw.githubusercontent.com/carrie0307/MyNotes/master/img/f_measure.png)
    
* 微平均: 即Mic ro-averaging,是用于多分类问题中的衡量指标。微平均是在不考虑类别的情况下进行统计建立全局混淆矩阵，然后计算相应的指标。例如Precision和Recall的微评价计算公式如下,其中TP是正确预测为正样本的数量，FP是负样本被错误预测为正样本的数量，FN是正样本被错误预测为负样本的数量。

* 参考文章: https://zhuanlan.zhihu.com/p/30953081

![微评价](https://raw.githubusercontent.com/carrie0307/MyNotes/master/img/micro_measure.png)
    
* 宏平均：即Macro-averaging,是用于多分类问题中的衡量指标。宏平均是**首先分别对每个类比进行指标计算(例如,f1-score)**, 然后再对所有类别的指标求**算术平均**。
    

* 加权平均：加权平均是在计算每个类别对应指标后，将**该类别样本数量占总样本数量的比例作为权值**，结合已计算的指标进行**加权平均计算**；
    

* 准确率：即accuracy,是对所有样本进行考虑，计算所有正确分类样本的数量占总样本数量的比例。

* 计算接口:

```python

from sklearn.metrics import classification_report
classification_report(true_y, pred_y)

# Output:
#      precision    recall  f1-score   support

#            0       1.00      1.00      1.00      9441
#            1       1.00      0.99      0.99      1477
#            2       0.99      1.00      0.99      1292

#    micro avg       1.00      1.00      1.00     12210
#    macro avg       0.99      1.00      1.00     12210
# weighted avg       1.00      1.00      1.00     12210

# accuracy:  0.9981981981981982
```