# 谱聚类相关基础概念

* 拉普拉斯矩阵: 度矩阵减邻接矩阵

* 半正定矩阵: https://blog.csdn.net/asd136912/article/details/79146151

* 矩阵奇异值: 关于奇异值分解的例子：https://blog.csdn.net/u010099080/article/details/68060274

* 以下内容整理自[从拉普拉斯到谱聚类](https://blog.csdn.net/v_JULY_v/article/details/40738211)

    * 普聚类：所谓聚类（Clustering），就是要把一堆样本合理地分成两份或者K份。从图论的角度来说，聚类的问题就相当于一个图的分割问题。即给定一个图G = (V, E)，顶点集V表示各个样本，带权的边表示各个样本之间的相似度，谱聚类的目的便是要找到一种合理的分割图的方法，使得分割后形成若干个子图，连接不同子图的边的权重（相似度）尽可能低，同子图内的边的权重（相似度）尽可能高
* Ratio Cut计算和NormalizedCut计算
![图摘自UCA何世柱老师slides](https://raw.githubusercontent.com/carrie0307/MyNotes/master/img/cut_cal.png)

其中|A<sub>i</sub>|是|A<sub>i</sub>|中节点数目，cut<A,B>是A,B两集合中连接点权值之和

* 谱聚类步骤(http://www.cnblogs.com/Leo_wl/p/3156049.html#_label1_2)

    * 第一步：数据准备，生成图的邻接矩阵；

    * 第二步：归一化普拉斯矩阵；

    * 第三步：生成最小的k个特征值和对应的特征向量；

    * 第四步：将特征向量kmeans聚类(少量的特征向量)；)

* 一般谱聚类代码: https://blog.csdn.net/Waleking/article/details/7584084
```python
#coding=utf-8
#MSC means Multiple Spectral Clustering 
import numpy as np
import scipy as sp
import scipy.linalg as linalg
import networkx as nx
import matplotlib.pyplot as plt
 
def getNormLaplacian(W):
    """input matrix W=(w_ij)
    "compute D=diag(d1,...dn)
    "and L=D-W
    "and Lbar=D^(-1/2)LD^(-1/2)
    "return Lbar
    """
    """
    W是邻接矩阵
    """
    d=[np.sum(row) for row in W]
    D=np.diag(d)
    # D是对邻接矩阵求和后的对角线部分，即度矩阵
    L=D-W
    #L是拉普拉斯矩阵
    #Dn=D^(-1/2)
    Dn=np.power(np.linalg.matrix_power(D,-1),0.5)
    Lbar=np.dot(np.dot(Dn,L),Dn)
    return Lbar
 
def getKSmallestEigVec(Lbar,k):
    """input
    "matrix Lbar and k
    "return
    "k smallest eigen values and their corresponding eigen vectors
    """
    # 返回了特征值和特征向量
    eigval,eigvec=linalg.eig(Lbar)
    dim=len(eigval)
 
    #查找前k小的eigval
    dictEigval=dict(zip(eigval,range(0,dim)))
    kEig=np.sort(eigval)[0:k]
    # 用前k小的特征值去字典中查询对应的特征向量
    ix=[dictEigval[k] for k in kEig]
    return eigval[ix],eigvec[:,ix]
 
def checkResult(Lbar,eigvec,eigval,k):
    """
    "input
    "matrix Lbar and k eig values and k eig vectors
    "print norm(Lbar*eigvec[:,i]-lamda[i]*eigvec[:,i])
    """
    check=[np.dot(Lbar,eigvec[:,i])-eigval[i]*eigvec[:,i] for i in range(0,k)]
    length=[np.linalg.norm(e) for e in check]/np.spacing(1)
    print("Lbar*v-lamda*v are %s*%s" % (length,np.spacing(1)))

# 创建有点的图 
g=nx.karate_club_graph()
nodeNum=len(g.nodes())
m=nx.to_numpy_matrix(g)
Lbar=getNormLaplacian(m)
k=2
# 得到特征值和特征向量
kEigVal,kEigVec=getKSmallestEigVec(Lbar,k)
print("k eig val are %s" % kEigVal)
print("k eig vec are %s" % kEigVec)
checkResult(Lbar,kEigVec,kEigVal,k)
 
#跳过k means，用最简单的符号判别的方法来求点的归属
 
clusterA=[i for i in range(0,nodeNum) if kEigVec[i,1]>0]
clusterB=[i for i in range(0,nodeNum) if kEigVec[i,1]<0]
 
#draw graph
# 节点序号作为字典的key
colList=dict.fromkeys(g.nodes())
for node,score in colList.items():
    if node in clusterA:
        colList[node]=0
    else:
        colList[node]=0.6
plt.figure(figsize=(8,8))
pos=nx.spring_layout(g)
nx.draw_networkx_edges(g,pos,alpha=0.4)
# nx.draw_networkx_nodes(g,pos,nodelist=colList.keys(), node_color=colList.values(),cmap=plt.cm.Reds_r)
nx.draw_networkx_nodes(g,pos,nodelist=colList.keys())
nx.draw_networkx_labels(g,pos,font_size=10,font_family='sans-serif')
plt.axis('off')
plt.title("karate_club spectral clustering")
plt.savefig("spectral_clustering_result.png")
plt.show()

```
