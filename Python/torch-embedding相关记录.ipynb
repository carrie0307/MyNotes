{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0868, -0.7985,  0.4803],\n",
       "        [-2.3194,  0.2405, -0.5583],\n",
       "        [-0.3008, -1.0022,  0.0396],\n",
       "        [ 1.7283,  2.3268,  1.2617],\n",
       "        [-1.4875, -0.0531,  0.8992],\n",
       "        [ 0.0131,  0.9614, -0.5288],\n",
       "        [ 0.6142, -0.4470, -0.3539],\n",
       "        [-1.0055,  2.6115,  0.9762],\n",
       "        [-1.4793, -0.7439, -0.0839],\n",
       "        [ 0.1275,  0.4703,  0.4038]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch embedding加载词向量与训练词向量\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    加载词向量    https://lyb3b.github.io/2017/12/12/pytorch%E5%8A%A0%E8%BD%BD%E5%B7%B2%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84word-embedding/ \n",
    "\"\"\"\n",
    "embedding = nn.Embedding(10, 3)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49044602, 0.56424827, 0.03615954],\n",
       "       [0.37477997, 0.10547466, 0.75048304],\n",
       "       [0.81672492, 0.53194183, 0.90856952],\n",
       "       [0.60222615, 0.18638102, 0.92762805],\n",
       "       [0.13413598, 0.63928688, 0.28781084],\n",
       "       [0.44410181, 0.79891153, 0.60051962],\n",
       "       [0.50259244, 0.42316361, 0.5855377 ],\n",
       "       [0.52200995, 0.26287504, 0.96355167],\n",
       "       [0.3351849 , 0.14383304, 0.41424016],\n",
       "       [0.54760257, 0.12300922, 0.82974449]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_word_embeds = np.random.rand(10, 3)\n",
    "pre_word_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.4904, 0.5642, 0.0362],\n",
       "        [0.3748, 0.1055, 0.7505],\n",
       "        [0.8167, 0.5319, 0.9086],\n",
       "        [0.6022, 0.1864, 0.9276],\n",
       "        [0.1341, 0.6393, 0.2878],\n",
       "        [0.4441, 0.7989, 0.6005],\n",
       "        [0.5026, 0.4232, 0.5855],\n",
       "        [0.5220, 0.2629, 0.9636],\n",
       "        [0.3352, 0.1438, 0.4142],\n",
       "        [0.5476, 0.1230, 0.8297]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是通过nn.Embedding()加载已训练好向量的方法；根据[文档](https://pytorch.org/docs/stable/nn.html)， nn.Embedding()是A simple lookup table that stores embeddings of a **fixed dictionary** and size., 因此无法对此进行训练，如果要训练，则应该使用ebm = nn.Embedding.from_pretrained(init_weight, freeze=False)，这样可以对emb.weight进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练后，可通过model.state_dict()['embed.weight']获取参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
