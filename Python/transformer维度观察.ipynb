{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a9da089770>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer多头attention维度观察\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 7, 2, 5, 6, 7, 6, 6],\n",
       "        [2, 2, 3, 8, 6, 7, 6, 7]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.randint(1,9,(2,8))\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 4, 2, 7, 1, 8, 4, 8],\n",
       "        [4, 6, 7, 8, 6, 2, 5, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = torch.randint(1,9,(2,8))\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  2 d_model:  8 head:  4 d_k:  2\n"
     ]
    }
   ],
   "source": [
    "batch=2\n",
    "d_model=8\n",
    "head=4\n",
    "d_k = 8 // head\n",
    "print (\"batch: \", batch, \"d_model: \", d_model, \"head: \", head, \"d_k: \", d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[8, 7],\n",
      "          [2, 5],\n",
      "          [6, 7],\n",
      "          [6, 6]]],\n",
      "\n",
      "\n",
      "        [[[2, 2],\n",
      "          [3, 8],\n",
      "          [6, 7],\n",
      "          [6, 7]]]])\n",
      "tensor([[[[6, 4],\n",
      "          [2, 7],\n",
      "          [1, 8],\n",
      "          [4, 8]]],\n",
      "\n",
      "\n",
      "        [[[4, 6],\n",
      "          [7, 8],\n",
      "          [6, 2],\n",
      "          [5, 6]]]])\n"
     ]
    }
   ],
   "source": [
    "query = query.view(2,-1,head,d_k)\n",
    "key = key.view(2,-1,head,d_k)\n",
    "print (query)\n",
    "print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_ = key.transpose(-2,-1)\n",
    "key_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[6, 2, 1, 4],\n",
       "          [4, 7, 8, 8]]],\n",
       "\n",
       "\n",
       "        [[[4, 7, 6, 5],\n",
       "          [6, 8, 2, 6]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[76, 65, 64, 88],\n",
       "          [32, 39, 42, 48],\n",
       "          [64, 61, 62, 80],\n",
       "          [60, 54, 54, 72]]],\n",
       "\n",
       "\n",
       "        [[[20, 30, 16, 22],\n",
       "          [60, 85, 34, 63],\n",
       "          [66, 98, 50, 72],\n",
       "          [66, 98, 50, 72]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.matmul(query,key_)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[76, 65, 64, 88],\n",
      "          [32, 39, 42, 48],\n",
      "          [64, 61, 62, 80],\n",
      "          [60, 54, 54, 72]]],\n",
      "\n",
      "\n",
      "        [[[20, 30, 16, 22],\n",
      "          [60, 85, 34, 63],\n",
      "          [66, 98, 50, 72],\n",
      "          [66, 98, 50, 72]]]])\n",
      "torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "scores = score // math.sqrt(d_k)\n",
    "print (scores)\n",
    "print (scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3, 4],\n",
       "          [6, 3],\n",
       "          [5, 8],\n",
       "          [2, 5]]],\n",
       "\n",
       "\n",
       "        [[[5, 8],\n",
       "          [7, 1],\n",
       "          [8, 2],\n",
       "          [3, 2]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.randint(1,9,(2,8))\n",
    "value = value.view(2,-1,head,d_k)\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6.1442e-06, 1.0262e-10, 3.7751e-11, 9.9999e-01],\n",
      "          [1.1224e-07, 1.2309e-04, 2.4723e-03, 9.9740e-01],\n",
      "          [1.1254e-07, 5.6028e-09, 1.5230e-08, 1.0000e+00],\n",
      "          [6.1442e-06, 1.5230e-08, 1.5230e-08, 9.9999e-01]]],\n",
      "\n",
      "\n",
      "        [[[4.5383e-05, 9.9962e-01, 8.3121e-07, 3.3533e-04],\n",
      "          [1.3888e-11, 1.0000e+00, 7.0955e-23, 2.7895e-10],\n",
      "          [1.2664e-14, 1.0000e+00, 1.4252e-21, 5.1091e-12],\n",
      "          [1.2664e-14, 1.0000e+00, 1.4252e-21, 5.1091e-12]]]])\n",
      "torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "scores = scores.float()\n",
    "p_attn = softmax(scores)\n",
    "print (p_attn)\n",
    "print (p_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.matmul(p_attn, value.float()) # [batch_size,1,4,4] matmul [batch_size,1,4,2] --- [batch_size,1,4,2]\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = output.transpose(1, 2).view(batch, -1, head * d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 8])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原代码地址:[Pytorch-Attention](https://github.com/harvardnlp/annotated-transformer/blob/master/The%20Annotated%20Transformer.ipynb)\n",
    "1. multi_head体现在对特征维度上进行reshape(batch,-1,head,d_k)得到若干个子空间，分别在子空间上计算attention\n",
    "2. 多头计算后的concat同样通过view进行，例如Line60\n",
    "3. 注意torch.matmul的用法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
